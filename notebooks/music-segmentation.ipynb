{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only uncomment and run once in your terminal.  If you're running as a notebook, you may need to reload for this to work.\n",
    "\n",
    "# !conda env create -f ./envs/segmenter-environment.yml\n",
    "# !conda activate segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.misc\n",
    "from scipy.spatial.distance import cdist\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pychorus import find_and_output_chorus\n",
    "from pychorus import create_chroma\n",
    "from pychorus.similarity_matrix import TimeTimeSimilarityMatrix, TimeLagSimilarityMatrix, Line\n",
    "import msaf\n",
    "import sys\n",
    "\n",
    "from math import isinf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Denoising size in seconds\n",
    "SMOOTHING_SIZE_SEC = 2.5\n",
    "\n",
    "# Number of samples to consider in one chunk.\n",
    "# Smaller values take more time, but are more accurate\n",
    "N_FFT = 2**3\n",
    "\n",
    "# For line detection\n",
    "LINE_THRESHOLD = 0.15\n",
    "MIN_LINES = 10\n",
    "NUM_ITERATIONS = 20\n",
    "\n",
    "# We allow an error proportional to the length of the clip\n",
    "OVERLAP_PERCENT_MARGIN = 0.2\n",
    "\n",
    "def local_maxima_rows(denoised_time_lag):\n",
    "    \"\"\"Find rows whose normalized sum is a local maxima\"\"\"\n",
    "    row_sums = np.sum(denoised_time_lag, axis=1)\n",
    "    divisor = np.arange(row_sums.shape[0], 0, -1)\n",
    "    normalized_rows = row_sums / divisor\n",
    "    local_minima_rows = scipy.signal.argrelextrema(normalized_rows, np.greater)\n",
    "    return local_minima_rows[0]\n",
    "\n",
    "\n",
    "def detect_lines(denoised_time_lag, rows, min_length_samples):\n",
    "    \"\"\"Detect lines in the time lag matrix. Reduce the threshold until we find enough lines\"\"\"\n",
    "    cur_threshold = LINE_THRESHOLD\n",
    "    for _ in range(NUM_ITERATIONS):\n",
    "        line_segments = detect_lines_helper(denoised_time_lag, rows,\n",
    "                                            cur_threshold, min_length_samples)\n",
    "        if len(line_segments) >= MIN_LINES:\n",
    "            return line_segments\n",
    "        cur_threshold *= 0.95\n",
    "\n",
    "    return line_segments\n",
    "\n",
    "\n",
    "def detect_lines_helper(denoised_time_lag, rows, threshold,\n",
    "                        min_length_samples):\n",
    "    \"\"\"Detect lines where at least min_length_samples are above threshold\"\"\"\n",
    "    num_samples = denoised_time_lag.shape[0]\n",
    "    line_segments = []\n",
    "    cur_segment_start = None\n",
    "    for row in rows:\n",
    "        if row < min_length_samples:\n",
    "            continue\n",
    "        for col in range(row, num_samples):\n",
    "            if denoised_time_lag[row, col] > threshold:\n",
    "                if cur_segment_start is None:\n",
    "                    cur_segment_start = col\n",
    "            else:\n",
    "                if (cur_segment_start is not None\n",
    "                   ) and (col - cur_segment_start) > min_length_samples:\n",
    "                    line_segments.append(Line(cur_segment_start, col, row))\n",
    "                cur_segment_start = None\n",
    "    return line_segments\n",
    "\n",
    "def count_overlapping_lines(lines, margin, min_length_samples):\n",
    "    \"\"\"Look at all pairs of lines and see which ones overlap vertically and diagonally\"\"\"\n",
    "    line_scores = {}\n",
    "    for line in lines:\n",
    "        line_scores[line] = 0\n",
    "\n",
    "    # Iterate over all pairs of lines\n",
    "    for line_1 in lines:\n",
    "        for line_2 in lines:\n",
    "            # If line_2 completely covers line_1 (with some margin), line_1 gets a point\n",
    "            lines_overlap_vertically = (\n",
    "                line_2.start < (line_1.start + margin)) and (\n",
    "                    line_2.end > (line_1.end - margin)) and (\n",
    "                        abs(line_2.lag - line_1.lag) > min_length_samples)\n",
    "\n",
    "            lines_overlap_diagonally = (\n",
    "                (line_2.start - line_2.lag) < (line_1.start - line_1.lag + margin)) and (\n",
    "                    (line_2.end - line_2.lag) > (line_1.end - line_1.lag - margin)) and (\n",
    "                        abs(line_2.lag - line_1.lag) > min_length_samples)\n",
    "\n",
    "            if lines_overlap_vertically or lines_overlap_diagonally:\n",
    "                line_scores[line_1] += 1\n",
    "\n",
    "    return line_scores\n",
    "\n",
    "def sorted_segments(line_scores):\n",
    "    \"\"\"Return the p line, sorted first by chorus matches, then by duration\"\"\"\n",
    "    lines_to_sort = []\n",
    "    for line in line_scores:\n",
    "        lines_to_sort.append((line, line_scores[line], line.end - line.start))\n",
    "\n",
    "    lines_to_sort.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    return lines_to_sort\n",
    "\n",
    "def fastdtw(x, y, dist, warp=1):\n",
    "    \"\"\"Returns the similarity between two song segments using dynamic time warping algorithm\"\"\"\n",
    "    \"\"\"Uses mfcc as the feature of comparison\"\"\"\n",
    "    assert len(x)\n",
    "    assert len(y)\n",
    "    if np.ndim(x) == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if np.ndim(y) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    r, c = len(x), len(y)\n",
    "    D0 = np.zeros((r + 1, c + 1))\n",
    "    D0[0, 1:] = np.inf\n",
    "    D0[1:, 0] = np.inf\n",
    "    D1 = D0[1:, 1:]\n",
    "    D0[1:, 1:] = cdist(x, y, dist)\n",
    "    C = D1.copy()\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            min_list = [D0[i, j]]\n",
    "            for k in range(1, warp + 1):\n",
    "                min_list += [D0[min(i + k, r), j],\n",
    "                             D0[i, min(j + k, c)]]\n",
    "            D1[i, j] += min(min_list)\n",
    "    return D1[-1, -1] / sum(D1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cello.wav...\n",
      "Processing jandl.mp3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/parse.c:skip_junk():1276] error: Giving up searching valid MPEG header after 65536 bytes of junk.\n",
      "[src/libmpg123/parse.c:skip_junk():1276] error: Giving up searching valid MPEG header after 65536 bytes of junk.\n"
     ]
    }
   ],
   "source": [
    "# file_name = '../audio/jandl.mp3'\n",
    "\n",
    "import os\n",
    "# Define the directory containing your audio files\n",
    "audio_directory = '../audio/'\n",
    "\n",
    "audio_files = [f for f in os.listdir(audio_directory) if f.endswith('.mp3') or f.endswith('.wav')]\n",
    "#read in the song and create a chromagram based off of the song\n",
    "#chroma, song_wav_data, sr, song_length_sec = create_chroma(\"../audio/\" + file_name)\n",
    "\n",
    "def process_audio_file(file_name):\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    \n",
    "    #read in the song and create a chromagram based off of the song\n",
    "    chroma, song_wav_data, sr, song_length_sec = create_chroma(os.path.join(audio_directory, file_name))\n",
    "    \n",
    "    #novelty based segmentation and labeling\n",
    "    boundaries, labels = msaf.process(os.path.join(audio_directory, file_name), \n",
    "                                    feature=\"mfcc\", \n",
    "                                    boundaries_id=\"foote\",\n",
    "                                    labels_id=\"fmc2d\", \n",
    "                                    out_sr=sr)\n",
    "\n",
    "    new_boundaries = []\n",
    "    new_labels = []\n",
    "    mfccs = []\n",
    "    #parse out segments longer than 5 seconds, and grab the mel frequency coefficients\n",
    "    for x in range(len(boundaries) - 1):\n",
    "        if boundaries[x + 1] - boundaries[x] >= 5:\n",
    "            segment_wav_data = song_wav_data[int(boundaries[x]*sr) : int(boundaries[x + 1]*sr)]\n",
    "            mel_freq = librosa.feature.mfcc(segment_wav_data, sr)\n",
    "            new_boundaries.append(boundaries[x])\n",
    "            new_labels.append(labels[x])\n",
    "            mfccs.append(np.average(mel_freq, axis=0))\n",
    "\n",
    "\n",
    "    num_samples = chroma.shape[1]\n",
    "    #create the time time and time lag similarity matrices\n",
    "    time_time_similarity = TimeTimeSimilarityMatrix(chroma, sr)\n",
    "    time_lag_similarity = TimeLagSimilarityMatrix(chroma, sr)\n",
    "\n",
    "\n",
    "    chroma_sr = num_samples / song_length_sec\n",
    "    clip_length = 10\n",
    "    smoothing_size_samples = int(SMOOTHING_SIZE_SEC * chroma_sr)\n",
    "\n",
    "    #denoise the time lag similarity matrix\n",
    "    time_lag_similarity.denoise(time_time_similarity.matrix,\n",
    "                                smoothing_size_samples)\n",
    "\n",
    "    clip_length_samples = clip_length * chroma_sr\n",
    "\n",
    "    candidate_rows = local_maxima_rows(time_lag_similarity.matrix)\n",
    "    #detect the lines from the time lag similarity matrix\n",
    "    lines = detect_lines(time_lag_similarity.matrix, candidate_rows,\n",
    "                        clip_length_samples)\n",
    "\n",
    "    if len(lines) == 0:\n",
    "        print(\"No repeating segments were detected.\")\n",
    "        sys.exit(-1)\n",
    "\n",
    "    #count the overlapping lines, and sort them\n",
    "    line_scores = count_overlapping_lines(\n",
    "        lines, OVERLAP_PERCENT_MARGIN * clip_length_samples,\n",
    "        clip_length_samples)\n",
    "\n",
    "    choruses = sorted_segments(line_scores)\n",
    "\n",
    "    unsorted_chorus_times = []\n",
    "    #find the start and stop times of each segment\n",
    "    for c in choruses:\n",
    "        unsorted_chorus_times.append((c[0].start / chroma_sr, c[0].end / chroma_sr))\n",
    "\n",
    "    #sort each segment chronologically\n",
    "    unsorted_chorus_times.sort(key=lambda x: x[0])\n",
    "\n",
    "    chorus_times = []\n",
    "    #get rid of segments that overlap each other\n",
    "    chorus_times.append(unsorted_chorus_times[0])\n",
    "    for i in range(1, len(unsorted_chorus_times)):\n",
    "        if (unsorted_chorus_times[i][0] - chorus_times[-1][0]) >= clip_length:\n",
    "            chorus_times.append(unsorted_chorus_times[i])\n",
    "\n",
    "\n",
    "    max_onset = 0\n",
    "    best_chorus = []\n",
    "    #get potential chorus segments between 10 and 30 seconds, and then use onset detection\n",
    "    #to find the best potential chorus section\n",
    "    for time in chorus_times:\n",
    "        if 10 <= (time[1] - time[0]) and (time[1] - time[0]) <= 30:\n",
    "            chorus_wave_data = song_wav_data[int(time[0]*sr) : int(time[1]*sr)]\n",
    "            onset_detect = librosa.onset.onset_detect(chorus_wave_data, sr)\n",
    "            if np.mean(onset_detect) >= max_onset:\n",
    "                max_onset = np.mean(onset_detect)\n",
    "                best_chorus = chorus_wave_data\n",
    "\n",
    "    #take the mfcc of the best chorus segment\n",
    "    chorus_mfcc = np.average(librosa.feature.mfcc(best_chorus, sr), axis=0)\n",
    "\n",
    "    structure_labels = [\"\"] * len(new_labels)\n",
    "\n",
    "    #calculate the dtw similarity between each segment and the detected chorus segment\n",
    "    #also detect the minimum and maximum distance values\n",
    "    max_dist = 0\n",
    "    min_dist = 100\n",
    "    similarity_measures = []\n",
    "    euclidean_norm = lambda x, y: np.abs(x - y)\n",
    "    for x in range(len(new_boundaries)):\n",
    "        dist = fastdtw(mfccs[x], chorus_mfcc, dist=euclidean_norm)\n",
    "        similarity_measures.append(dist)\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "\n",
    "    #normalize the similarity measures and sort\n",
    "    normalized = [float(i)/max(similarity_measures) for i in similarity_measures]\n",
    "    sorted_norms = sorted(normalized)\n",
    "\n",
    "    #normalize the threshold; songs with larger ranges, take a lower threshold value,\n",
    "    #whereas for songs for a higher range, take a higher threshold\n",
    "    bottom = []\n",
    "    if max_dist - min_dist <= 2:\n",
    "        bottom = sorted_norms[int(len(sorted_norms) * 0) : int(len(sorted_norms) * .5)]\n",
    "    else:\n",
    "        bottom = sorted_norms[int(len(sorted_norms) * 0) : int(len(sorted_norms) * .40)]\n",
    "\n",
    "    #if the calculated dtw similarity value for a segment is below the normalized threshold,\n",
    "    #that segment is labeled the chorus\n",
    "    for x in range(len(structure_labels)):\n",
    "        if normalized[x] <= bottom[-1]:\n",
    "            structure_labels[x] = \"chorus\"\n",
    "\n",
    "    #label the other segments -- repeating non chorus segments are considered verses,\n",
    "    #transitions are unique segments that appear in the middle of a song,\n",
    "    #and intros and outros are unique segments that appear at the beginning and ending\n",
    "    #of a song respectively\n",
    "    for x in range(len(structure_labels)):\n",
    "        found_match = False\n",
    "        for y in range(x + 1, len(structure_labels)):\n",
    "            if (new_labels[x] == new_labels[y]) and structure_labels[y] == \"\"  and structure_labels[x] == \"\":\n",
    "                found_match = True\n",
    "                structure_labels[x] = \"verse\"\n",
    "                structure_labels[y] = \"verse\"\n",
    "        if found_match == False and structure_labels[x] == \"\":\n",
    "            if x == 0:\n",
    "                structure_labels[x] = \"intro\"\n",
    "            elif x == (len(new_boundaries) - 1):\n",
    "                structure_labels[x] = \"outro\"\n",
    "            else:\n",
    "                structure_labels[x] = \"transition\"\n",
    "\n",
    "    #write the labels to a text file, to be used in Audacity\n",
    "    with open(\"../labels/\" + file_name + \"_labels.txt\", \"w\") as frames:\n",
    "        for e in range(len(new_boundaries)):\n",
    "            if e < len(new_boundaries) - 1:\n",
    "                outer_bound = e + 1\n",
    "                frames.write(f\"{round(new_boundaries[e])}\\t{round(new_boundaries[outer_bound])}\\t{structure_labels[e]}\\n\")\n",
    "            else:\n",
    "                frames.write(f\"{round(new_boundaries[e])}\\t{round(song_length_sec)}\\t{structure_labels[e]}\\n\")\n",
    "\n",
    "for file_name in audio_files:\n",
    "    try:\n",
    "        process_audio_file(file_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {str(e)}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmenter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
