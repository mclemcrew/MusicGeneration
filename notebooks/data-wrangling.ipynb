{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation\n",
    "\n",
    "Here we have to do the following:\n",
    "- Load all the wav files from the corpus\n",
    "  - Separate out the individual instruments with the audio itself\n",
    "    - Separate out the individual instruments and convert to MIDI\n",
    "    - Verify the MIDI data for each\n",
    "- Creating of sections based on the timestamps\n",
    "  - From the MIDI data, loop through and make sure that each note is in the correct section with the correct label\n",
    "- Loading of the metadata from the corpus as well (we have differing meta-data based on the captioning types of things here)\n",
    "- Any other data or notes will be here with everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install basic-pitch\n",
    "!pip install music21\n",
    "!pip install tensorflow\n",
    "!pip install librosa\n",
    "!python3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating out the individual stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"htdemucs_ft\"\n",
    "extensions = [\"mp3\", \"wav\", \"ogg\", \"flac\"]  # we will look for all those file types.\n",
    "two_stems = None   # only separate one stems from the rest, for instance\n",
    "\n",
    "# Options for the output audio.\n",
    "mp3 = True\n",
    "mp3_rate = 320\n",
    "float32 = False  # output as float 32 wavs, unsused if 'mp3' is True.\n",
    "int24 = False    # output as int24 wavs, unused if 'mp3' is True.\n",
    "\n",
    "in_path = '../audio/'\n",
    "out_path = '../audio/stems/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Useful functions, don't forget to execute\n",
    "import io\n",
    "from pathlib import Path\n",
    "import select\n",
    "from shutil import rmtree\n",
    "import subprocess as sp\n",
    "import sys\n",
    "from typing import Dict, Tuple, Optional, IO\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "def find_files(in_path):\n",
    "    out = []\n",
    "    for file in Path(in_path).iterdir():\n",
    "        if file.suffix.lower().lstrip(\".\") in extensions:\n",
    "            out.append(file)\n",
    "    return out\n",
    "\n",
    "def copy_process_streams(process: sp.Popen):\n",
    "    def raw(stream: Optional[IO[bytes]]) -> IO[bytes]:\n",
    "        assert stream is not None\n",
    "        if isinstance(stream, io.BufferedIOBase):\n",
    "            stream = stream.raw\n",
    "        return stream\n",
    "\n",
    "    p_stdout, p_stderr = raw(process.stdout), raw(process.stderr)\n",
    "    stream_by_fd: Dict[int, Tuple[IO[bytes], io.StringIO, IO[str]]] = {\n",
    "        p_stdout.fileno(): (p_stdout, sys.stdout),\n",
    "        p_stderr.fileno(): (p_stderr, sys.stderr),\n",
    "    }\n",
    "    fds = list(stream_by_fd.keys())\n",
    "\n",
    "    while fds:\n",
    "        # `select` syscall will wait until one of the file descriptors has content.\n",
    "        ready, _, _ = select.select(fds, [], [])\n",
    "        for fd in ready:\n",
    "            p_stream, std = stream_by_fd[fd]\n",
    "            raw_buf = p_stream.read(2 ** 16)\n",
    "            if not raw_buf:\n",
    "                fds.remove(fd)\n",
    "                continue\n",
    "            buf = raw_buf.decode()\n",
    "            std.write(buf)\n",
    "            std.flush()\n",
    "\n",
    "def separate(inp=None, outp=None):\n",
    "    inp = inp or in_path\n",
    "    outp = outp or out_path\n",
    "    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(outp), \"-n\", model]\n",
    "    if mp3:\n",
    "        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n",
    "    if float32:\n",
    "        cmd += [\"--float32\"]\n",
    "    if int24:\n",
    "        cmd += [\"--int24\"]\n",
    "    if two_stems is not None:\n",
    "        cmd += [f\"--two-stems={two_stems}\"]\n",
    "    files = [str(f) for f in find_files(inp)]\n",
    "    if not files:\n",
    "        print(f\"No valid audio files in {in_path}\")\n",
    "        return\n",
    "    print(\"Going to separate the files:\")\n",
    "    print('\\n'.join(files))\n",
    "    print(\"With command: \", \" \".join(cmd))\n",
    "    p = sp.Popen(cmd + files, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    copy_process_streams(p)\n",
    "    p.wait()\n",
    "    if p.returncode != 0:\n",
    "        print(\"Command failed, something went wrong.\")\n",
    "\n",
    "\n",
    "def from_upload():\n",
    "    out_path = Path('separated')\n",
    "    in_path = Path('tmp_in')\n",
    "    \n",
    "    if in_path.exists():\n",
    "        rmtree(in_path)\n",
    "    in_path.mkdir()\n",
    "    \n",
    "    if out_path.exists():\n",
    "        rmtree(out_path)\n",
    "    out_path.mkdir()\n",
    "    \n",
    "    separate(in_path, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "from basic_pitch.inference import predict_and_save, Model\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "\n",
    "basic_pitch_model = Model(ICASSP_2022_MODEL_PATH)\n",
    "\n",
    "audio_directory = '../audio/test/'\n",
    "audio_files = glob.glob(audio_directory + '*.mp3')\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    # Estimate BPM using librosa\n",
    "    print(audio_file)\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    \n",
    "    tempo = int(round(tempo[0]))\n",
    "    print(f\"Tempo: {tempo}\")\n",
    "\n",
    "    predict_and_save(\n",
    "        audio_path_list=[audio_file],\n",
    "        output_directory='../midi/',\n",
    "        save_model_outputs=True,\n",
    "        save_midi=True,\n",
    "        sonify_midi=True,\n",
    "        save_notes=True,\n",
    "        minimum_note_length=127.70,\n",
    "        model_or_model_path=basic_pitch_model,\n",
    "        onset_threshold=0.5,\n",
    "        frame_threshold=0.3,\n",
    "        sonification_samplerate=44100,\n",
    "        midi_tempo=tempo  # Use estimated tempo here\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "midi_file = music21.converter.parse('../midi/01 - Ravi Krishnaswami - 0598_copilot_basic_pitch.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
